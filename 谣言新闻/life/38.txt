昨天，雷锋网(公众号：雷锋网)撰文《爆料：曹旭东创立自动驾驶公司Momenta首次公开项目细节》，正式公布曹旭东及其创业项目Momenta，此项目致力于打造自动驾驶大脑，核心技术是基于深度学习的环境感知、高精度地图、驾驶决策算法。产品包括不同级别的自动驾驶方案，以及衍生出的大数据服务。文章发布后，很多读者对于这个携带深度学习再一次袭来的自动驾驶公司涌现了很多疑问，曹旭东特此从技术角度详细回答了关于Momenta的8个质疑，全文如下。1问：为什么选择无人驾驶创业？曹旭东：个体和环境的交互能激发智能。我选择人工智能及其具体子方向，是基于两个基本的原则：生产力和自由。正如工业革命将人从繁重危险的体力劳动中解放出来，人工智能的革命能将人从枯燥重复的脑力劳动中解放出来。另一方面，人工智能让我们有更多的时间精力，去学习、去想象、去创造，实现更自由之精神。更自由，是Momenta合伙人孙环从人文视角提出的见解。生产力发展是物理世界的趋势，追求自由则是精神世界的趋势，虽然出发点不同、视角不同，然而两者殊途同归。大数据和智能。人工智能先驱西蒙有一个深刻的观点：智能是个体和环境之间互动的总和。举个例子，一种浮游生物，前半生在环境复杂的海域中游荡，为了应对恶劣的生存环境，它有大脑，有智力；后半生则附着在礁石，因为环境简单稳定，所以它的大脑消失了，没有智力。这个例子生动地说明了个体和环境的交互能激发智能。大数据，就是人类理解智能、实现智能的基础。我相信未来世界的生产力和自由，将来自大数据和智能，这是我选择无人驾驶方向的原因。从去年年初，我开始思考无人驾驶的技术路径和商业路径，虽然现在的理解已经比一年多前成熟很多，但仍有一些地方没想明白。人在看不清前路的时候，很容易因为困难而放弃。对于基本原则的信念，就像是数学上证明了解的存在性，即使发现此路不通，也能保持乐观，不停探索，直至实现目标。任少卿：让机器感受世界。我之所以创业，有三个原因。第一个原因是我的梦想——一直以来，我想让机器感受世界。我毕业于中国科技大学与微软亚洲研究院联合培养博士班，一直从事科研工作，现在正在通过人工视觉实现自己的目标。在实现目标的过程中，神经网络的发展明显成为了我们的瓶颈，对我们形成了不小的挑战。但是我相信探索的过程也正是求知的过程，求知，是给自己的生命增加浓度。求知欲驱动我做出人生的每一个大小决定。第二个原因是无人驾驶是一个朝阳行业。深度学习的无人驾驶技术本身是一个较为年轻的领域，更新换代的速度非常快。青年人强大的学习能力，是我们进入该领域的得天独厚的优势。中国拥有广阔的市场，为行业未来的发展前景提供了强大的保障。第三个原因是我想创业——我深知这是自己一生中必然要经历的事情。既然迟早要发生，那不如放手一搏、把握当下，趁着年轻赶紧行动。Momenta这个朝气蓬勃的团队，最大的特点是言行合一，具有极高的创造力和行动力，相互之间的沟通非常顺畅。我喜欢在这样的一个团体里简单而执着地做好每一件事。在初创公司创业和在大公司工作，其工作环境、工作体验以及可能遇到的问题都不一样。我认为两者最大的差异，是创业过程中我们会面对各种全新的、前所未知的东西，而我热爱这份披荆斩棘、乘风破浪的前进感。2问：你们团队最大的优势是什么？曹旭东：现阶段来说，最大的优势是深度学习算法能力。长期来看，团队最大的优势是一群有梦想的年轻人。他们有活力，善学习，能创新，有冲劲，带动公司一起快速成长。我们的深度学习能力，可分为逐层递进的三个层面，分别是单点能力、方案能力和平台能力。单点能力指基础算法能力，如检测、识别、分割等基础任务。我们团队有世界领先水平的创新力和竞争力。创新力方面，任少卿是Faster-RCNN的第一作者和ResNet的第三作者，这两个方法是现在学术界主流的物体检测和图像识别算法。竞争力方面，孙刚团队分别获得ImageNet场景识别2015年冠军和2016年亚军，任少卿2015年获得ImageNet，MSCOCO Challenge多项冠军，曹旭东获得美国National DataScienceBowl亚军。这些比赛含金量很高，有明确关门时间，有强劲的对手，如Google，Facebook，Oxford等世界强队。方案能力是指定义问题并形成解决方案的能力。在学术界，九成以上的研究中，数据集和测试标准都是给定的，学者们主要研究单点算法。然而，工业界的问题却是开放的，我们需要考虑不同定义问题的方式，考虑如何多快好省的生产数据，考虑不同测试标准的优劣，需要探索多种技术路径，定位技术路径中的关键节点并进行重点突破。创业中，拥有全面的视野很重要。纯学术背景的人经常一开始就钻进一个单点算法，但是数据集本身可能是脏的，评测指标和目标不一致，导致技术路径出现错误，最后做了无用功。我们团队不仅有出色的研究背景，更有多年工业界的实战经验，善于进行问题导向的创新研究，能够有效地解决实际问题。平台能力是指搭建共享平台、提高整体效率的能力。（1）数据平台。如何多快好省地生产数据是我们最重要的研究课题之一，我们通过非监督、算法辅助、渲染生成等方式生产大量标注数据。除此之外，团队正在构建的标注平台可以把标注成本降低到市面价格的1/3~1/4。（2）训练平台。现在数百块GPU组成的训练平台支持我们的算法实验，实现快速迭代，充分发挥每一个研究员的创新能力，能做到“不让想法等机器”。（3）模型平台。现在论文常常使用ResNet/GoogleNet/VGGNet，给人一种错觉，深度学习模型只有这么几种。实战中，通过巧妙设计模型结构、训练过程、学习目标等，我们可以将模型提速10~100倍，模型压缩100倍，精度几乎不受损失。这是我们在产品方面重要的竞争力之一。以上三个层面的概括了我们深度学习能力。3问：你觉得无人驾驶最大难点是什么？无人驾驶，最重要的是安全。高安全性意味着低事故率。一个系统做到很低的事故率，通常要做两件事情，一个是发现问题，一个是解决问题。在刚开始的时候，由于系统的问题非常多，主要的精力在解决问题，但是随着事故率逐渐降低，发现问题变得越来越难。据统计，全球来看，对于人类司机，一亿公里发生致命事故一至三起。对于无人驾驶，我们希望比人更安全，最好致命事故率低一个量级，做到十亿公里一起致命性事故。统计上，要达到足够置信度，需要多次重复实验，最好一百次以上。这意味着一套比人更加安全的无人驾驶的系统需要测试的总里程达到1000亿公里。按照一辆车一年10万公里总里程计算。我们需要100万辆车，一整年的时间，收集无人驾驶数据和测试，才能够保证无人驾驶所需要的安全性。现在Google和百度的无人车成本都在百万人民币量级，乘以100万辆车这个巨大的基数，对于任何一家公司而言，都是一个天文数字。4问：你是如何看待现在多家厂商宣称已经开展了无人货车、客车、出租的试运营？最近新闻上看到了很多无人车试运营的报道，比如，Uber和nuTonumy分别在美国和新加坡开展了无人出租的试运营。个人认为这是市场营销上一个讨巧的说法，让人误以为这些公司已经开始商业落地，在技术和应用上都快人一步。但本质上，大家做的都是无人车路测。谷歌现在有几十辆车左右在美国的多个城市同时进行路测。相比于谷歌，其他各家公司的无人车路测数量和总里程更少。总的来说，无论是十辆车试运行还是一百辆车试运行，都是在做无人车的demo，如果没有解决无人车大规模数据收集和测试的关键问题，demo到商业化落地之间的巨大鸿沟就会一直存在。以谷歌为例，谷歌在2009年就已经开始了高速路测，在2012年的时候已经开始了城市道路测试，积累的总里程最近超过了500万公里，且没有发生一起致命事故。这已经是非常了不起的成就了。但是谷歌的路测实验并不能说明总里程达到一亿公里的时候不会发生致命事故，不能说明现在谷歌的无人驾驶技术的安全性已经超过了人类驾驶。可能当谷歌的无人车的数量从100辆车扩展到10万辆车，增加了1000倍的时候，一年就会发生几十起甚至几百起致命事故。这些交通事故将会对谷歌无人车业务造成致命性的打击。这正是谷歌无人车从09年开始持续进行多年科技研发，投入了大量成本，却迟迟没有商业化的关键原因。5 问：你们的公司是如何解决这个关键问题，达到足够的安全性？我们回到刚才的分析，无人车大规模数据收集和测试的巨大成本主要来源于两方面。一方面是需要海量的测试车辆，另一方面是高昂的单车成本。针对这两方面的成本，我们有两种互补的解决方案——第一种解决方案是无人驾驶模拟；第二种解决方案是众包数据收集和测试。无人驾驶模拟可以通过算法生成感知和决策数据，减少数据收集和测试车辆数量，降低研发成本。当然，无人驾驶模拟也存在不足。第一，模拟生成的感知数据和真实的数据存在差异，实际中，还是以真实数据为主，生成数据为辅。第二，模拟的规则是人制定的。很多失败的场景恰恰是人思考的盲点，单纯通过模拟并不能发现。总结来说，虽然模拟可以降低数据收集和测试车辆的数量，但是我们仍然需要收集真实数据，用大量的车做真实测试。单车成本主要由三部分构成：设备成本，造车成本，运营成本。运营成本就是驾驶员开着车采数据和做测试的成本。设备成本方面，我们可以发挥算法优势，通过多摄像头等廉价设备实现无人驾驶。摄像头是所有感知设备中信息量最大的，需要人脑水平的强人工智能，才能从间接视频数据中提取出无人驾驶所需要的直接数据。激光雷达、高精GPS和IMU长期看都有降价空间，我们的技术方案不排除任何感知设备，价格合理，就会融合进来。造车成本和运营成本已经优化了上百年，很难降低。一个聪明的想法是让其他人承担这部分成本——这个想法叫做众包，代表性的公司有特斯拉和Mobileye。然而，遗憾的是，他们的众包方案存在两个问题：一，需要造车。特斯拉自己造车，Mobileye则通过合作伙伴造车。二，需要读取和控制车辆驾驶行为。造车周期三到五年，显著慢于算法研发节奏，成为时间瓶颈。如果为了加快迭代，在算法没成熟的情况下强行上车，是拿人的生命做冒险，也显然不可取。特斯拉的几起致命事故就是血的教训。因此，我们设想直接利用现有道路上已有的运营车辆，不需要造车、改车、控制车，以一种零负担、零危险的方式实现众包测试和数据收集，这是个非常困难的问题，需要非常深厚的算法积淀和原创能力。6问：什么是高精地图（HD Map）？有什么价值？高精地图是一个宽泛的概念，需要达到两方面的高精度。高精度一方面体现在地标位置的高精度。高精地图由很多类地标构成，比如地面各种道路标线，地上各种交通标志等，地标的定义现在还没有明确的标准，不同厂商从自己产品和技术需求出发，有不同的定义方式。高精度另一方面体现在本车定位的高精度。高精定位有三种方式：第一种是卫星定位。多基站+差分GPS在开阔区域可以做到厘米级精度，但是城市中因为多路径效应，精度只有米；第二种是匹配定位，这种方式和人很像，观察周围环境或者地标，在记忆地图中搜索，匹配定位。结合GPS限定搜索范围，可以做到快速准确匹配。第三种是积分定位。IMU或者视觉里程计。短时间内精确，长时间有累积误差。这三种方式各有优缺点，结合起来可以做到低成本、高精度、高可靠性。高精度地图是视觉的延伸和增强，之于无人驾驶是必须的。举个例子，多车道弯道行车时，因为路旁障碍物的遮挡，车载传感器感知不到拐弯之后的道路情况，导致拐弯之后的某一车道上发生车祸。一旦有了高精地图的车道级定位和实时路况更新，就能提前减速并变换到到非车祸车道，杜绝事故的发生 。再举一个例子：通过视觉，我们可以识别当前在第几车道，通过高精度地图定位，我们也可以知道当前在第几车道，两种不同方式互相校验，可以达到更高的安全性。总结来说，高精地图可以使无人车看得更远，看得更准。高精地图对于自动驾驶整体解决方案研发的价值非常高，这一点却被很多人忽视。分三个方面：决策，测试，V2E。第一方面，无人驾驶决策。本质上，驾驶决策学习的是道路环境到驾驶行为的映射，也就是这种情况应该怎么开，那种情况应该怎么开。如果获得环境和行为的海量数据，就可以通过数据驱动的方式学习无人驾驶决策。道路环境可以通过视觉感知获得，而司机的驾驶行为如何获得？很多人认为，司机的驾驶行为就是刹车油门方向盘，想要获得，一定要有CAN总线权限，要改车。其实不需要。首先，更新一个概念，司机的驾驶行为还可以用车辆在高精地图中的轨迹表示。通过精确定位，我们可以获得每辆车的驾驶轨迹，以及轨迹上每一点的速度，加速度。驾驶轨迹是驾驶行为更通用的表示，与车型无关。刹车油门方向盘，虽然直观，但不通用。人类司机，换辆车，要调整驾驶习惯，重新适应，是同一道理。依赖高精地图，我们可以获得驾驶轨迹这一驾驶行为数据。通过众包，就可以获得海量环境和行为数据，通过数据驱动的方式学习无人驾驶决策。第二方面，无人驾驶测试。测试，找出问题，非常重要，也极具挑战。当无人驾驶算法接近人类驾驶的安全性时，需要一千辆车测试一年的时间才有可能发现问题。如果团队像Google和百度一样靠自己运营测试车辆，显然是不现实的。众包是唯一实现海量测试的方法，但是我们不希望像特斯拉一样，以消费者的生命为代价，测试自己未成熟的算法方案。通过高精度地图，我们不控制车、不带来危险，就可以实现众包测试。具体原理是，我们可以预测驾驶轨迹，也记录了真实驾驶轨迹。预测轨迹和真实轨迹比对，如果一致，说明测试通过，如果不一致，说明测试失败。找到问题，就可以有的放矢，高效解决问题。我们的方法是为无人车大脑测试设计的。无人驾驶整体测试还包括无人车身体测试，以及身体和大脑结合的测试，也就是车辆测试和轨迹跟踪测试。相比于无人车大脑，这两部分成熟很多。第三方面，V2E。V2E是指通过车辆和道路通信实现无人驾驶。概念上，V2E可以大大降低无人驾驶的难度，提高安全性。非常有意思的是，这个概念在特定场景早已商业化，例如亚马逊的仓储机器人Kiva。仓库地下铺设有通信导轨，每个搬运机器人实时和导轨通信，确定自己当前的位置，接受中心计算机的调度。中心计算机知道所有机器人的当前状态，根据取货需求，整体规划调度每个机器人取货送货。但是将V2E的概念真正落地到无人驾驶却困难重重，其中主要有三方面的问题。第一，道路通信设备要解决供电、应对风吹日晒雨淋等技术可靠性问题，还要承担基础设施重建和复杂维护的高昂成本。二，环境和车辆通信，需要统一的通信标准。谁来制定标准？众多车企都以自己的利益为考虑，很难协调。三，通信安全的问题。如果黑客或者恐怖分子利用通信协议漏洞，恶意操纵路面上的车辆，制造恐怖事件，又应如何应对？这些问题都限制了V2E从概念短期内走向现实。相对于电子通信的V2E，我们提出“渐进式的V2E”。无人驾驶的很多问题是因为道路标线、标牌不足或者布置不合理造成的，通过高精地图和基于高精地图的测试，我们可以自动发现哪些路段标线和标识需要改进，并且给出改进的具体实施方案。渐进式V2E不需要电子通信设备，没有通信标准和安全问题。在现有道路标线、标牌体系下，就可以大幅改善无人驾驶的可靠性和安全性。7问：视觉高精度地图如何实现？是SLAM技术吗？不是SLAM也不是SFM，这些方法都不适用。要建真正可用的视觉高精地图，需要从第一原理出发重新设计整个算法。我们构建高精地图的第一原理是：多张图像存在视差，利用点的对应关系，可以从2D点恢复出3D点。人眼双目视觉获得深度也是这一原理。从基本原理出发，建立高精地图，需要创造性地解决三方面的问题：图像部分。检测识别语义点。传统的SLAM或者SFM算法都基于SIFT、ORB等人工设计的特征点。在光照、视角发生变化的情况下，无法准确的检测匹配原有特征点。换句话说，光照视角发生变化后，原来构建的地图就无法使用了。我们的方法是定义道路标线、标牌等地标上的点作为语义点，通过深度学习和数据驱动的监督训练得到模型，可以准确检测和识别语义点，解决检测不到、匹配错误的问题。几何部分。通过众包间接实现海量摄像头测量效果。不同车辆，不同时间，经过同一地标，即使光照视角不同，我们也可以通过语义点模型把所有车辆拍摄到的同一语义点关联起来，这相当于间接实现了多摄像头测距的效果。我们知道，视觉测量中，摄像头越多、视差覆盖越全，测量精度就越高。我们实验验证，随着众包车次的增加，真实3D点位置估计的准确性有量级上的提升。GPS部分。给每个语义点精确的GPS坐标。我们有几方面的考虑：(1)让高精地图通用。GPS坐标是地图的通用语言，给每个语义点赋予GPS坐标，便于他人使用；(2)消除累积误差。单纯使用几何方法构建局部地图，会有累积误差。结合GPS，可以解决这个问题；(3)消除局部地图歧义性。当局部地图有重合或者语义点缺失的时候，确定局部地图坐标系很麻烦，但全局GPS坐标系没有这个问题。8问：无人驾驶端到端的学习（end-to-endlearning）靠谱吗？端到端是深度学习中的一个概念，具体指通过深度学习网络直接学习从输入到输出的映射关系。无人驾驶端到端学习指的是输入视频序列、输出刹车油门方向盘的操作序列。英伟达和comma.ai都使用端到端深度学习，开发出了无人驾驶的demo系统。简单来说，对于无人驾驶，端到端不适合开发实用无人驾驶系统，可以做demo，然而大规模商用却非常困难，其原因如下：不聪明。我们在做驾驶决策时，只关心高精地图环境、自己当前位置和周围物体的相对位置，并不关心车的颜色或者路边的树叶是绿的还是黄的。端到端学习没有这些先验知识，所以需要大量冗余数据和计算。如果把整个无人驾驶拆解成感知、地图、决策三部分，分别独立学习再融合，可以大大降低需要的数据和计算。不灵活。端到端学习的是摄像头输入到刹车油门方向盘输出的直接映射。如果摄像头设置变化或者增加其他感知设备，就需要重新收集数据学习。如果换辆车，执行机构变化，也需要重新收集数据学习。如果拆解成感知、地图和决策三部分，就可以大大提高灵活性。比如模拟极端情况，我们只需要在高精地图图层中生成车辆3D框，不需要重新渲染真实道路环境和车辆视频，简单很多。难理解。无人驾驶是一个系统工程。遇到问题时，深入系统，诊断出问题模块，有针对性的改进，是解决问题的行之有效的手段。但是，对于整体端到端学习，一旦出现问题，因为无法对症下药，解决问题的难度会增大，需要投入更多的资源和时间。我并不是完全否定端到端学习，而是无人驾驶端到端学习目前存在以上问题，或许在将来可以得到解决。考验一个算法团队解决实际问题能力的一个重要的方面就是拆解问题——把一个复杂问题拆解成一系列比较简单的问题，再通过端到端深度学习解决。通常来说，在检测、识别、分割等简单基础的任务上，端到端学习可以获得更好的效果。复杂问题的拆解是一门艺术。雷锋网原创文章，转载请注明来源出处，详情请见转载须知 